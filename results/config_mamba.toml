[model]
model_name='mamba'
model_size='130m'
cache_dir='models'
answer_tokens = [' Yes', ' No']

[model.training]
output_dir='./results'
num_train_epochs=40
learning_rate=1e-5
per_device_train_batch_size=32
per_device_eval_batch_size=32
warmup_ratio=0.1 
#eval_strategy='steps'
logging_strategy='steps'
logging_steps=500
save_strategy='epoch'
weight_decay=0.01
logging_dir='./logs'
seed=42
report_to='wandb'

[model.LoRA]
inference_mode=false   
r=8            
lora_alpha=32    
lora_dropout=0.1  
target_modules=['x_proj', 'embeddings', 'in_proj', 'out_proj']
bias='none'

[dataset]
cache_dir='datasets'

[dataset.train]
dataset_name='snli'
dataset_split='train'

[[dataset.test]]
dataset_name='snli'
dataset_split='test'

[[dataset.test]]
dataset_name='mnli'
dataset_split='validation_matched'

[[dataset.test]]  
dataset_name='scitail'
dataset_split='test'

[[dataset.test]]  
dataset_name='wnli'
dataset_split='train'

[[dataset.test]]  
dataset_name='rte'
dataset_split='train'

[[dataset.test]]  
dataset_name='paws'
dataset_split='test'

[[dataset.test]]  
dataset_name='hans'
dataset_split='validation'

[[dataset.test]]  
dataset_name='anli'
dataset_split='test_r3'